{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from astropy.io import ascii\n",
    "from utils import *\n",
    "from scipy.stats import skew, kurtosis\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = \"../datasets/SuperCOSMOS/\"\n",
    "uki823_df =ascii.read(datasets + \"UKI823/sssedrpair.dat\", guess=False, Reader=ascii.FastNoHeader).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uki823_df.columns = col_names\n",
    "#ukr823_df.columns = col_names\n",
    "#ukj823_df.columns = col_names\n",
    "uki823_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uki823_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalise SDSS class labels. Form confusion matrix\n",
    "normalise_sdss_class(uki823_df)\n",
    "uki823_df[['CLASS', 'CLASS_SDSS']]\n",
    "confusion_matrix(uki823_df['CLASS'], uki823_df['CLASS_SDSS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create first raw dataset\n",
    "data_x_raw = uki823_df.iloc[:,:-1]\n",
    "data_y_raw =uki823_df['CLASS_SDSS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split raw dataset into raw train,val,test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "random_state = 1\n",
    "X_train_raw,X_test_raw,y_train,y_test = train_test_split(data_x_raw,data_y_raw,test_size=0.1,random_state=random_state)\n",
    "X_train_raw,X_val_raw,y_train,y_val = train_test_split(X_train_raw,y_train,test_size=2./9,random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_raw = X_train_raw.reset_index(drop=True)\n",
    "X_val_raw = X_val_raw.reset_index(drop=True)\n",
    "X_test_raw = X_test_raw.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "y_val = y_val.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "\n",
    "X_train_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define classification function\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score,roc_auc_score\n",
    "\n",
    "def Classify_Function(x_train,y_train,x_val,y_val):\n",
    "    names = [\"Logistic Regression\", #\"Linear SVM\", \"RBF SVM\",\n",
    "             \"Decision Tree\", \"Random Forest\", \"Neural Net (Multi-layer perceptron)\"]\n",
    "\n",
    "    classifiers = [\n",
    "        LogisticRegression(),\n",
    "        SVC(kernel=\"linear\", probability=True, random_state=random_state),\n",
    "        #SVC(kernel='rbf', probability=True, random_state=random_state),\n",
    "        DecisionTreeClassifier(max_depth=10),\n",
    "        RandomForestClassifier(max_depth=10, n_estimators=50,random_state=random_state),\n",
    "        MLPClassifier(max_iter=1000, random_state=random_state)]\n",
    "\n",
    "    ca_score = {} # Classification accuracy\n",
    "    F1_scores = {} #F1 scores\n",
    "    tr_score = {}\n",
    "    tr_F1 = {}\n",
    "\n",
    "    for name, clf in zip(names, classifiers):\n",
    "        clf.fit(x_train, y_train)\n",
    "        tr_score[name] = clf.score(x_train, y_train)\n",
    "        ca_score[name] = clf.score(x_val, y_val)\n",
    "        tr_F1[name] = f1_score(y_train, clf.predict(x_train), average='macro')\n",
    "        F1_scores[name] = f1_score(y_val,clf.predict(x_val),average='macro')\n",
    "\n",
    "    print('Classification performance on validation set:')\n",
    "    for clf in names:\n",
    "        print (\"{}, training accuracy: {:.3f}, training f1: {:.3f}\".format(clf, tr_score[clf], tr_F1[clf]))\n",
    "        print (\"{}, accuracy: {:.3f}, f1-score: {:.3f}\\n\\n\".format(clf, ca_score[clf], F1_scores[clf]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# #Classify the raw data\n",
    "# Classify_Function(X_train_raw,y_train,X_val_raw,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# labels = np.array([1,2])\n",
    "# fig, ax = plt.subplots((len(X_train_raw.columns)), labels.size, figsize=(15,45), sharey = 'row', sharex = 'row')\n",
    "\n",
    "\n",
    "# for ii, feat in enumerate(X_train_raw):\n",
    "#     for jj, clas in enumerate(labels):\n",
    "#         sns.distplot(X_train_raw[y_train==clas][feat], ax=ax[ii][jj], kde=True)\n",
    "#         ax[ii][jj].xaxis.label.set_visible(False)\n",
    "           \n",
    "# [ax[0][ii].set_title(\"Class {}\".format(clas)) for ii, clas in enumerate(labels)]\n",
    "# [ax[ii][0].set_ylabel(\"{}\".format(feat)) for ii, feat in enumerate(X_train_raw)]\n",
    "        \n",
    "# fig.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_raw.iloc[:,relevant_indices[0:(len(relevant_indices)-1)]]\n",
    "X_val = X_val_raw.iloc[:,relevant_indices[0:(len(relevant_indices)-1)]]\n",
    "X_test = X_test_raw.iloc[:,relevant_indices[0:(len(relevant_indices)-1)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AREA', 'IPEAK', 'COSMAG', 'ISKY', 'A_U', 'B_U', 'THETA_U', 'A_I',\n",
       "       'B_I', 'THETA_I', 'BLEND', 'QUALITY', 'PRFMAG', 'C_COSMAG', 'C_PRFMAG',\n",
       "       'RA_SDSS', 'DEC_SDSS', 'GMAG_SDSS', 'RMAG_SDSS', 'IMAG_SDSS',\n",
       "       'ELLIPTICITY', 'FILLING_FACTOR'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extracting relevant columns and adding ellips and FF to X datasets\n",
    "X_train = add_filling_factor(add_ellipticity_df(X_train))\n",
    "X_val = add_filling_factor(add_ellipticity_df(X_val))\n",
    "X_test = add_filling_factor(add_ellipticity_df(X_test))\n",
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Identify features that look interesting...\n",
    "# interesting_cols = [0, 1, 2, 10, 11, 21]\n",
    "\n",
    "# # Need to add X_train and y_train back together here\n",
    "# temp = deepcopy(X_train)\n",
    "# temp['ys'] = y_train\n",
    "\n",
    "# sns.pairplot(temp, vars=X_train.columns[interesting_cols], hue='ys', diag_kind = 'kde', plot_kws={'s' : 6})\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale dataset and classify\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler().fit(X_train.astype('float64'))\n",
    "\n",
    "\n",
    "# Classify_Function(sc.transform(X_train.astype('float64')),\n",
    "#                   y_train,\n",
    "#                   sc.transform(X_val.astype('float64')),\n",
    "#                   y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Fitting PCA to scaled training data. 9 PC's\n",
    "# from sklearn.decomposition import PCA\n",
    "# pca = PCA().fit(sc.transform(X_train.astype('float64')))\n",
    "# print(np.cumsum(pca.explained_variance_ratio_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Calculate PCA scores for all datasets. 11 PCs\n",
    "# eleven_pcs = PCA(n_components = 11).fit(sc.transform(X_train.astype('float64')))\n",
    "# pc_scores_train = eleven_pcs.transform(sc.transform(X_train.astype('float64')))\n",
    "# pc_scores_val = eleven_pcs.transform(sc.transform(X_val.astype('float64')))\n",
    "# pc_scores_test = eleven_pcs.transform(sc.transform(X_test.astype('float64')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Define function to plot PC directions\n",
    "# def scatter_2d_label(X_2d, y, s=2, alpha=0.5, lw=2):\n",
    "#     \"\"\"Visualuse a 2D embedding with corresponding labels.\n",
    "    \n",
    "#     X_2d : ndarray, shape (n_samples,2)\n",
    "#         Low-dimensional feature representation.\n",
    "    \n",
    "#     y : ndarray, shape (n_samples,)\n",
    "#         Labels corresponding to the entries in X_2d.\n",
    "        \n",
    "#     s : float\n",
    "#         Marker size for scatter plot.\n",
    "    \n",
    "#     alpha : float\n",
    "#         Transparency for scatter plot.\n",
    "        \n",
    "#     lw : float\n",
    "#         Linewidth for scatter plot.\n",
    "#     \"\"\"\n",
    "#     targets = np.unique(y)\n",
    "#     colors = sns.color_palette(n_colors=targets.size)\n",
    "#     for color, target in zip(colors, targets):\n",
    "#         plt.scatter(X_2d[y == target, 0], X_2d[y == target, 1], color=color, label=target, s=s, alpha=alpha, lw=lw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dim_1 = 0# First dimension\n",
    "# dim_2 = 1 # Second dimension\n",
    "# plt.figure(figsize=(8,5)) # Initialise a figure instance with defined size\n",
    "# scatter_2d_label(pc_scores_train[:, [dim_1,dim_2]], y_train)\n",
    "# plt.legend(loc='center left', bbox_to_anchor=[1.01, 0.5], scatterpoints=3) # Add a legend outside the plot at specified point\n",
    "# plt.xlabel('Dim {}'.format(dim_1))\n",
    "# plt.ylabel('Dim {}'.format(dim_2))\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify_Function(pc_scores_train,y_train,pc_scores_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jsmyt\\Anaconda3\\envs\\dme_project\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Users\\jsmyt\\Anaconda3\\envs\\dme_project\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Users\\jsmyt\\Anaconda3\\envs\\dme_project\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()\n",
    "X=enc.fit_transform(X_train_raw['CLASS'].values.reshape(-1,1)).toarray()\n",
    "dfOneHot = pd.DataFrame(X, columns = [\"Class_\"+str(int(i)) for i in range(X.shape[1])])\n",
    "dfOneHot = pd.concat([dfOneHot, X_train_raw['N(0,1)']], axis=1)\n",
    "X_train_SSS = pd.concat([X_train, dfOneHot], axis=1)\n",
    "\n",
    "\n",
    "X=enc.fit_transform(X_val_raw['CLASS'].values.reshape(-1,1)).toarray()\n",
    "dfOneHot = pd.DataFrame(X, columns = [\"Class_\"+str(int(i)) for i in range(X.shape[1])])\n",
    "dfOneHot = pd.concat([dfOneHot, X_val_raw['N(0,1)']], axis=1)\n",
    "X_val_SSS = pd.concat([X_val, dfOneHot], axis=1)\n",
    "\n",
    "\n",
    "X=enc.fit_transform(X_test_raw['CLASS'].values.reshape(-1,1)).toarray()\n",
    "dfOneHot = pd.DataFrame(X, columns = [\"Class_\"+str(int(i)) for i in range(X.shape[1])])\n",
    "dfOneHot = pd.concat([dfOneHot, X_test_raw['N(0,1)']], axis=1)\n",
    "X_test_SSS = pd.concat([X_test, dfOneHot], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " sc2 = StandardScaler().fit(X_train_SSS.astype('float64'))\n",
    "\n",
    "\n",
    "# Classify_Function(sc2.transform(X_train_SSS.astype('float64')),\n",
    "#                   y_train,\n",
    "#                   sc2.transform(X_val_SSS.astype('float64')),\n",
    "#                   y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Classifying the test set\n",
    "# sc3 = StandardScaler().fit(X_train.astype('float64'))\n",
    "# #sc3.transform(X_train.astype('float64'))\n",
    "# final_names = [\"Random Forest\", \"Neural Net (Multi-layer perceptron)\"]\n",
    "# final_classifiers = [RandomForestClassifier(max_depth=10, n_estimators=50,random_state=random_state),MLPClassifier(max_iter=1000, random_state=random_state)]\n",
    "\n",
    "# ca_score = {} # Classification accuracy\n",
    "# F1_scores = {} #F1 scores\n",
    "\n",
    "# for name, clf in zip(final_names, final_classifiers):\n",
    "#     clf.fit(sc3.transform(X_train.astype('float64')), y_train)\n",
    "#     ca_score[name] = clf.score(sc3.transform(X_test.astype('float64')), y_test)\n",
    "#     F1_scores[name] = f1_score(y_test,clf.predict(sc3.transform(X_test.astype('float64'))),average='macro')\n",
    "    \n",
    "# print('Classification performance on test set:')\n",
    "# for clf in final_names:\n",
    "#     print (\"{}, accuracy: {:.3f}, f1-score: {:.3f}\\n\\n\".format(clf, ca_score[clf], F1_scores[clf]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc2 = StandardScaler().fit(X_train_SSS.astype('float64'))\n",
    "X_train_SSS_sc= sc2.transform(X_train_SSS.astype('float64'))\n",
    "X_val_SSS_sc = sc2.transform(X_val_SSS.astype('float64'))\n",
    "X_test_SSS_sc = sc2.transform(X_test_SSS.astype('float64'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backwards Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " %%time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# # # Build a classification task using 3 informative features\n",
    "# # X, y = make_classification(n_samples=1000, n_features=25, n_informative=3,\n",
    "# #                            n_redundant=2, n_repeated=0, n_classes=8,\n",
    "# #                            n_clusters_per_class=1, random_state=0)\n",
    "\n",
    "# # Create the RFE object and compute a cross-validated score.\n",
    "# svc = SVC(kernel=\"linear\")\n",
    "# # The \"accuracy\" scoring is proportional to the number of correct\n",
    "# # classifications\n",
    "# rfecv = RFECV(estimator=svc, step=1, cv=StratifiedKFold(2),\n",
    "#               scoring='accuracy')\n",
    "# rfecv.fit(X_train_SSS, y_train)\n",
    "\n",
    "# print(\"Optimal number of features : %d\" % rfecv.n_features_)\n",
    "\n",
    "# # Plot number of features VS. cross-validation scores\n",
    "# plt.figure()\n",
    "# plt.xlabel(\"Number of features selected\")\n",
    "# plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "# plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "##############################################################\n",
    "\n",
    "##Non SVC##\n",
    "# # Build a classification task using 3 informative features\n",
    "# X, y = make_classification(n_samples=1000, n_features=25, n_informative=3,\n",
    "#                            n_redundant=2, n_repeated=0, n_classes=8,\n",
    "#                            n_clusters_per_class=1, random_state=0)\n",
    "\n",
    "# Create the RFE object and compute a cross-validated score.\n",
    "rfc=SVC(kernel=\"linear\", probability=True, random_state=random_state)\n",
    "# The \"accuracy\" scoring is proportional to the number of correct\n",
    "# classifications\n",
    "rfecv = RFECV(estimator=rfc, step=1, cv=StratifiedKFold(2),\n",
    "              scoring='accuracy')\n",
    "rfecv.fit(X_train_SSS, y_train)\n",
    "\n",
    "print(\"Optimal number of features : %d\" % rfecv.n_features_)\n",
    "\n",
    "# Plot number of features VS. cross-validation scores\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train_SSS.columns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind_list=['AREA', 'IPEAK', 'COSMAG', 'ISKY', 'A_U', 'B_U', 'A_I', 'B_I', 'PRFMAG',\n",
    "       'C_COSMAG', 'C_PRFMAG', 'GMAG_SDSS', 'RMAG_SDSS', 'IMAG_SDSS',\n",
    "       'ELLIPTICITY', 'FILLING_FACTOR', 'Class_3']\n",
    "type(ind_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get indices of most important variables\n",
    "# ind_list=[]\n",
    "# for i in range(len(X_train.columns)):\n",
    "#     if rfecv.ranking_[i] == 1:\n",
    "#         ind_list.append(i)\n",
    "var_list=['AREA', 'IPEAK', 'COSMAG', 'ISKY', 'A_U', 'B_U', 'A_I', 'B_I', 'PRFMAG',\n",
    "       'C_COSMAG', 'C_PRFMAG', 'GMAG_SDSS', 'RMAG_SDSS', 'IMAG_SDSS',\n",
    "       'ELLIPTICITY', 'FILLING_FACTOR', 'Class_3']\n",
    "\n",
    "ind_list=[]\n",
    "for i in range(len(X_train_SSS.columns)):\n",
    "    if X_train_SSS.columns[i] in var_list:\n",
    "        ind_list.append(i)\n",
    "        \n",
    "bwe_data_train = X_train_SSS_sc[:, ind_list]\n",
    "bwe_data_val=X_val_SSS_sc[:,ind_list]\n",
    "bwe_data_test=X_test_SSS_sc[:,ind_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1565, 27)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_SSS.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10951, 17)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bwe_data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Order of colums originally:  Index(['AREA', 'IPEAK', 'COSMAG', 'ISKY', 'A_U', 'B_U', 'THETA_U', 'A_I',\n",
      "       'B_I', 'THETA_I', 'BLEND', 'QUALITY', 'PRFMAG', 'C_COSMAG', 'C_PRFMAG',\n",
      "       'RA_SDSS', 'DEC_SDSS', 'GMAG_SDSS', 'RMAG_SDSS', 'IMAG_SDSS',\n",
      "       'ELLIPTICITY', 'FILLING_FACTOR'],\n",
      "      dtype='object')\n",
      "\n",
      "\n",
      "Indexes of variables selected:  [0, 1, 2, 3, 4, 5, 7, 8, 12, 13, 14, 17, 18, 19, 20, 21, 25]\n",
      "\n",
      "\n",
      "Actual variables selected:  Index(['AREA', 'IPEAK', 'COSMAG', 'ISKY', 'A_U', 'B_U', 'A_I', 'B_I', 'PRFMAG',\n",
      "       'C_COSMAG', 'C_PRFMAG', 'GMAG_SDSS', 'RMAG_SDSS', 'IMAG_SDSS',\n",
      "       'ELLIPTICITY', 'FILLING_FACTOR', 'Class_3'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print('Order of colums originally: ', X_train.columns)\n",
    "print('\\n')\n",
    "print('Indexes of variables selected: ',ind_list)\n",
    "print('\\n')\n",
    "print('Actual variables selected: ',X_train_SSS.columns[ind_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bwe_data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bwe_data_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify_Function(sc2.transform(bwe_data_train.astype('float64')),\n",
    "#                   y_train,\n",
    "#                   sc2.transform(bwe_data_val.astype('float64')),\n",
    "#                   y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jsmyt\\Anaconda3\\envs\\dme_project\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification performance on validation set:\n",
      "Logistic Regression, accuracy: 0.870, f1-score: 0.862\n",
      "Linear SVM, accuracy: 0.874, f1-score: 0.866\n",
      "RBF SVM, accuracy: 0.881, f1-score: 0.875\n",
      "Decision Tree, accuracy: 0.903, f1-score: 0.897\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Random Forest'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-a159e02ea2bb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Classification performance on validation set:'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"{}, accuracy: {:.3f}, f1-score: {:.3f}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mca_score\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mF1_scores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m: 'Random Forest'"
     ]
    }
   ],
   "source": [
    "\n",
    "names = [\"Logistic Regression\", \"Linear SVM\", \"RBF SVM\",\n",
    "         \"Decision Tree\", \"Random Forest\", \"Neural Net (Multi-layer perceptron)\"]\n",
    "\n",
    "classifiers = [\n",
    "    LogisticRegression(),\n",
    "#     SVC(kernel=\"linear\", probability=True, random_state=random_state),\n",
    "#     SVC(kernel='rbf', probability=True, random_state=random_state),\n",
    "    DecisionTreeClassifier(max_depth=10),\n",
    "    RandomForestClassifier(max_depth=10, n_estimators=50,random_state=random_state),\n",
    "    MLPClassifier(max_iter=1000, random_state=random_state)]\n",
    "\n",
    "ca_score = {} # Classification accuracy\n",
    "F1_scores = {} #F1 scores\n",
    "\n",
    "for name, clf in zip(names, classifiers):\n",
    "    clf.fit(bwe_data_train, y_train)\n",
    "    ca_score[name] = clf.score(bwe_data_val, y_val)\n",
    "    F1_scores[name] = f1_score(y_val,clf.predict(bwe_data_val),average='macro')\n",
    "    \n",
    "print('Classification performance on validation set:')\n",
    "for clf in names:\n",
    "    print (\"{}, accuracy: {:.3f}, f1-score: {:.3f}\".format(clf, ca_score[clf],F1_scores[clf]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
