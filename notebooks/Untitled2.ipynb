{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from astropy.io import ascii\n",
    "from utils import *\n",
    "from scipy.stats import skew, kurtosis\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = \"../datasets/SuperCOSMOS/\"\n",
    "uki823_df = ascii.read(datasets + \"UKI823/sssedrpair.dat\").to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RA</th>\n",
       "      <th>DEC</th>\n",
       "      <th>XMIN</th>\n",
       "      <th>XMAX</th>\n",
       "      <th>YMIN</th>\n",
       "      <th>YMAX</th>\n",
       "      <th>AREA</th>\n",
       "      <th>IPEAK</th>\n",
       "      <th>COSMAG</th>\n",
       "      <th>ISKY</th>\n",
       "      <th>...</th>\n",
       "      <th>N(0,1)</th>\n",
       "      <th>PRFMAG</th>\n",
       "      <th>C_COSMAG</th>\n",
       "      <th>C_PRFMAG</th>\n",
       "      <th>RA_SDSS</th>\n",
       "      <th>DEC_SDSS</th>\n",
       "      <th>GMAG_SDSS</th>\n",
       "      <th>RMAG_SDSS</th>\n",
       "      <th>IMAG_SDSS</th>\n",
       "      <th>CLASS_SDSS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>627905166</td>\n",
       "      <td>-1862044</td>\n",
       "      <td>22405186</td>\n",
       "      <td>22421181</td>\n",
       "      <td>10590948</td>\n",
       "      <td>10604948</td>\n",
       "      <td>161</td>\n",
       "      <td>42793408</td>\n",
       "      <td>-22923</td>\n",
       "      <td>17532226</td>\n",
       "      <td>...</td>\n",
       "      <td>-777</td>\n",
       "      <td>-23019</td>\n",
       "      <td>15.639</td>\n",
       "      <td>14.998</td>\n",
       "      <td>359.763288</td>\n",
       "      <td>-1.067042</td>\n",
       "      <td>19.127230</td>\n",
       "      <td>17.637123</td>\n",
       "      <td>15.888538</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>628109952</td>\n",
       "      <td>-662364</td>\n",
       "      <td>21782348</td>\n",
       "      <td>21792346</td>\n",
       "      <td>14279944</td>\n",
       "      <td>14289944</td>\n",
       "      <td>46</td>\n",
       "      <td>5089298</td>\n",
       "      <td>-20025</td>\n",
       "      <td>18211806</td>\n",
       "      <td>...</td>\n",
       "      <td>4639</td>\n",
       "      <td>-20435</td>\n",
       "      <td>17.703</td>\n",
       "      <td>17.800</td>\n",
       "      <td>359.880409</td>\n",
       "      <td>-0.379610</td>\n",
       "      <td>19.122244</td>\n",
       "      <td>18.505545</td>\n",
       "      <td>18.302338</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>628195987</td>\n",
       "      <td>-1076412</td>\n",
       "      <td>21517417</td>\n",
       "      <td>21529414</td>\n",
       "      <td>13006944</td>\n",
       "      <td>13018944</td>\n",
       "      <td>87</td>\n",
       "      <td>17260390</td>\n",
       "      <td>-21479</td>\n",
       "      <td>17841694</td>\n",
       "      <td>...</td>\n",
       "      <td>-51</td>\n",
       "      <td>-21669</td>\n",
       "      <td>16.723</td>\n",
       "      <td>16.460</td>\n",
       "      <td>359.929869</td>\n",
       "      <td>-0.616716</td>\n",
       "      <td>19.118631</td>\n",
       "      <td>17.716108</td>\n",
       "      <td>17.013582</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>628311942</td>\n",
       "      <td>-518403</td>\n",
       "      <td>21162509</td>\n",
       "      <td>21172507</td>\n",
       "      <td>14721942</td>\n",
       "      <td>14731942</td>\n",
       "      <td>57</td>\n",
       "      <td>7749678</td>\n",
       "      <td>-20599</td>\n",
       "      <td>18688688</td>\n",
       "      <td>...</td>\n",
       "      <td>-259</td>\n",
       "      <td>-20958</td>\n",
       "      <td>17.357</td>\n",
       "      <td>17.232</td>\n",
       "      <td>359.996295</td>\n",
       "      <td>-0.297037</td>\n",
       "      <td>19.114597</td>\n",
       "      <td>18.120455</td>\n",
       "      <td>17.692406</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>627218041</td>\n",
       "      <td>-1032678</td>\n",
       "      <td>24519637</td>\n",
       "      <td>24532633</td>\n",
       "      <td>13137958</td>\n",
       "      <td>13149958</td>\n",
       "      <td>84</td>\n",
       "      <td>14814466</td>\n",
       "      <td>-21295</td>\n",
       "      <td>17692354</td>\n",
       "      <td>...</td>\n",
       "      <td>111</td>\n",
       "      <td>-21519</td>\n",
       "      <td>16.848</td>\n",
       "      <td>16.623</td>\n",
       "      <td>359.369486</td>\n",
       "      <td>-0.591688</td>\n",
       "      <td>19.112507</td>\n",
       "      <td>17.852146</td>\n",
       "      <td>17.173191</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          RA      DEC      XMIN      XMAX      YMIN      YMAX  AREA     IPEAK  \\\n",
       "0  627905166 -1862044  22405186  22421181  10590948  10604948   161  42793408   \n",
       "1  628109952  -662364  21782348  21792346  14279944  14289944    46   5089298   \n",
       "2  628195987 -1076412  21517417  21529414  13006944  13018944    87  17260390   \n",
       "3  628311942  -518403  21162509  21172507  14721942  14731942    57   7749678   \n",
       "4  627218041 -1032678  24519637  24532633  13137958  13149958    84  14814466   \n",
       "\n",
       "   COSMAG      ISKY     ...      N(0,1)  PRFMAG  C_COSMAG  C_PRFMAG  \\\n",
       "0  -22923  17532226     ...        -777  -23019    15.639    14.998   \n",
       "1  -20025  18211806     ...        4639  -20435    17.703    17.800   \n",
       "2  -21479  17841694     ...         -51  -21669    16.723    16.460   \n",
       "3  -20599  18688688     ...        -259  -20958    17.357    17.232   \n",
       "4  -21295  17692354     ...         111  -21519    16.848    16.623   \n",
       "\n",
       "      RA_SDSS  DEC_SDSS  GMAG_SDSS  RMAG_SDSS  IMAG_SDSS  CLASS_SDSS  \n",
       "0  359.763288 -1.067042  19.127230  17.637123  15.888538           6  \n",
       "1  359.880409 -0.379610  19.122244  18.505545  18.302338           6  \n",
       "2  359.929869 -0.616716  19.118631  17.716108  17.013582           6  \n",
       "3  359.996295 -0.297037  19.114597  18.120455  17.692406           6  \n",
       "4  359.369486 -0.591688  19.112507  17.852146  17.173191           6  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uki823_df.columns = col_names\n",
    "#ukr823_df.columns = col_names\n",
    "#ukj823_df.columns = col_names\n",
    "uki823_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RA</th>\n",
       "      <th>DEC</th>\n",
       "      <th>XMIN</th>\n",
       "      <th>XMAX</th>\n",
       "      <th>YMIN</th>\n",
       "      <th>YMAX</th>\n",
       "      <th>AREA</th>\n",
       "      <th>IPEAK</th>\n",
       "      <th>COSMAG</th>\n",
       "      <th>ISKY</th>\n",
       "      <th>...</th>\n",
       "      <th>N(0,1)</th>\n",
       "      <th>PRFMAG</th>\n",
       "      <th>C_COSMAG</th>\n",
       "      <th>C_PRFMAG</th>\n",
       "      <th>RA_SDSS</th>\n",
       "      <th>DEC_SDSS</th>\n",
       "      <th>GMAG_SDSS</th>\n",
       "      <th>RMAG_SDSS</th>\n",
       "      <th>IMAG_SDSS</th>\n",
       "      <th>CLASS_SDSS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.564500e+04</td>\n",
       "      <td>1.564500e+04</td>\n",
       "      <td>1.564500e+04</td>\n",
       "      <td>1.564500e+04</td>\n",
       "      <td>1.564500e+04</td>\n",
       "      <td>1.564500e+04</td>\n",
       "      <td>15645.000000</td>\n",
       "      <td>1.564500e+04</td>\n",
       "      <td>15645.000000</td>\n",
       "      <td>1.564500e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>15645.000000</td>\n",
       "      <td>15645.000000</td>\n",
       "      <td>15645.000000</td>\n",
       "      <td>15645.000000</td>\n",
       "      <td>15645.000000</td>\n",
       "      <td>15645.000000</td>\n",
       "      <td>15645.000000</td>\n",
       "      <td>15645.000000</td>\n",
       "      <td>15645.000000</td>\n",
       "      <td>15645.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.037003e+08</td>\n",
       "      <td>8.493844e+04</td>\n",
       "      <td>2.101054e+07</td>\n",
       "      <td>2.102133e+07</td>\n",
       "      <td>1.657487e+07</td>\n",
       "      <td>1.658549e+07</td>\n",
       "      <td>92.001151</td>\n",
       "      <td>1.319364e+07</td>\n",
       "      <td>-20152.272867</td>\n",
       "      <td>1.808098e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>2716.035986</td>\n",
       "      <td>-20838.007670</td>\n",
       "      <td>17.481817</td>\n",
       "      <td>17.367207</td>\n",
       "      <td>174.007529</td>\n",
       "      <td>0.048635</td>\n",
       "      <td>19.528314</td>\n",
       "      <td>18.495397</td>\n",
       "      <td>17.893314</td>\n",
       "      <td>4.885331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.131201e+08</td>\n",
       "      <td>1.264880e+06</td>\n",
       "      <td>3.094560e+06</td>\n",
       "      <td>3.094725e+06</td>\n",
       "      <td>3.885662e+06</td>\n",
       "      <td>3.885580e+06</td>\n",
       "      <td>314.990581</td>\n",
       "      <td>1.817166e+07</td>\n",
       "      <td>1971.753396</td>\n",
       "      <td>4.441520e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>3628.301001</td>\n",
       "      <td>1759.041618</td>\n",
       "      <td>1.285655</td>\n",
       "      <td>1.894035</td>\n",
       "      <td>179.404607</td>\n",
       "      <td>0.724706</td>\n",
       "      <td>2.194382</td>\n",
       "      <td>1.931732</td>\n",
       "      <td>1.773068</td>\n",
       "      <td>1.449708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.440000e+02</td>\n",
       "      <td>-2.170521e+06</td>\n",
       "      <td>1.578191e+07</td>\n",
       "      <td>1.579490e+07</td>\n",
       "      <td>9.640962e+06</td>\n",
       "      <td>9.652950e+06</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.297920e+06</td>\n",
       "      <td>-28893.000000</td>\n",
       "      <td>1.709983e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>-8899.000000</td>\n",
       "      <td>-34317.000000</td>\n",
       "      <td>11.154000</td>\n",
       "      <td>4.781000</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>-1.243447</td>\n",
       "      <td>8.985260</td>\n",
       "      <td>6.618781</td>\n",
       "      <td>6.940934</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.761940e+05</td>\n",
       "      <td>-9.941590e+05</td>\n",
       "      <td>1.829625e+07</td>\n",
       "      <td>1.830425e+07</td>\n",
       "      <td>1.326194e+07</td>\n",
       "      <td>1.327096e+07</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>2.348600e+06</td>\n",
       "      <td>-21393.000000</td>\n",
       "      <td>1.769842e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>-21599.000000</td>\n",
       "      <td>16.776000</td>\n",
       "      <td>16.536000</td>\n",
       "      <td>0.502112</td>\n",
       "      <td>-0.569497</td>\n",
       "      <td>18.465448</td>\n",
       "      <td>17.573668</td>\n",
       "      <td>17.055212</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.691507e+06</td>\n",
       "      <td>1.317640e+05</td>\n",
       "      <td>2.097056e+07</td>\n",
       "      <td>2.098055e+07</td>\n",
       "      <td>1.671895e+07</td>\n",
       "      <td>1.672794e+07</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>3.912512e+06</td>\n",
       "      <td>-19703.000000</td>\n",
       "      <td>1.802993e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>2189.000000</td>\n",
       "      <td>-20233.000000</td>\n",
       "      <td>17.858000</td>\n",
       "      <td>18.019000</td>\n",
       "      <td>0.969110</td>\n",
       "      <td>0.075373</td>\n",
       "      <td>19.967171</td>\n",
       "      <td>18.960104</td>\n",
       "      <td>18.355196</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.274335e+08</td>\n",
       "      <td>1.190811e+06</td>\n",
       "      <td>2.367885e+07</td>\n",
       "      <td>2.368885e+07</td>\n",
       "      <td>1.997294e+07</td>\n",
       "      <td>1.998294e+07</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>1.417421e+07</td>\n",
       "      <td>-18561.000000</td>\n",
       "      <td>1.845908e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>4545.000000</td>\n",
       "      <td>-19562.000000</td>\n",
       "      <td>18.471000</td>\n",
       "      <td>18.748000</td>\n",
       "      <td>359.492904</td>\n",
       "      <td>0.682301</td>\n",
       "      <td>21.087143</td>\n",
       "      <td>19.793398</td>\n",
       "      <td>19.087181</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.283183e+08</td>\n",
       "      <td>2.222493e+06</td>\n",
       "      <td>2.651011e+07</td>\n",
       "      <td>2.654111e+07</td>\n",
       "      <td>2.313795e+07</td>\n",
       "      <td>2.315595e+07</td>\n",
       "      <td>24006.000000</td>\n",
       "      <td>1.210549e+08</td>\n",
       "      <td>-17410.000000</td>\n",
       "      <td>1.899585e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>102961.000000</td>\n",
       "      <td>-18962.000000</td>\n",
       "      <td>19.292000</td>\n",
       "      <td>19.399000</td>\n",
       "      <td>359.999933</td>\n",
       "      <td>1.273383</td>\n",
       "      <td>22.999374</td>\n",
       "      <td>24.802490</td>\n",
       "      <td>27.166468</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 RA           DEC          XMIN          XMAX          YMIN  \\\n",
       "count  1.564500e+04  1.564500e+04  1.564500e+04  1.564500e+04  1.564500e+04   \n",
       "mean   3.037003e+08  8.493844e+04  2.101054e+07  2.102133e+07  1.657487e+07   \n",
       "std    3.131201e+08  1.264880e+06  3.094560e+06  3.094725e+06  3.885662e+06   \n",
       "min    1.440000e+02 -2.170521e+06  1.578191e+07  1.579490e+07  9.640962e+06   \n",
       "25%    8.761940e+05 -9.941590e+05  1.829625e+07  1.830425e+07  1.326194e+07   \n",
       "50%    1.691507e+06  1.317640e+05  2.097056e+07  2.098055e+07  1.671895e+07   \n",
       "75%    6.274335e+08  1.190811e+06  2.367885e+07  2.368885e+07  1.997294e+07   \n",
       "max    6.283183e+08  2.222493e+06  2.651011e+07  2.654111e+07  2.313795e+07   \n",
       "\n",
       "               YMAX          AREA         IPEAK        COSMAG          ISKY  \\\n",
       "count  1.564500e+04  15645.000000  1.564500e+04  15645.000000  1.564500e+04   \n",
       "mean   1.658549e+07     92.001151  1.319364e+07 -20152.272867  1.808098e+07   \n",
       "std    3.885580e+06    314.990581  1.817166e+07   1971.753396  4.441520e+05   \n",
       "min    9.652950e+06      8.000000  1.297920e+06 -28893.000000  1.709983e+07   \n",
       "25%    1.327096e+07     17.000000  2.348600e+06 -21393.000000  1.769842e+07   \n",
       "50%    1.672794e+07     37.000000  3.912512e+06 -19703.000000  1.802993e+07   \n",
       "75%    1.998294e+07     92.000000  1.417421e+07 -18561.000000  1.845908e+07   \n",
       "max    2.315595e+07  24006.000000  1.210549e+08 -17410.000000  1.899585e+07   \n",
       "\n",
       "           ...              N(0,1)        PRFMAG      C_COSMAG      C_PRFMAG  \\\n",
       "count      ...        15645.000000  15645.000000  15645.000000  15645.000000   \n",
       "mean       ...         2716.035986 -20838.007670     17.481817     17.367207   \n",
       "std        ...         3628.301001   1759.041618      1.285655      1.894035   \n",
       "min        ...        -8899.000000 -34317.000000     11.154000      4.781000   \n",
       "25%        ...          153.000000 -21599.000000     16.776000     16.536000   \n",
       "50%        ...         2189.000000 -20233.000000     17.858000     18.019000   \n",
       "75%        ...         4545.000000 -19562.000000     18.471000     18.748000   \n",
       "max        ...       102961.000000 -18962.000000     19.292000     19.399000   \n",
       "\n",
       "            RA_SDSS      DEC_SDSS     GMAG_SDSS     RMAG_SDSS     IMAG_SDSS  \\\n",
       "count  15645.000000  15645.000000  15645.000000  15645.000000  15645.000000   \n",
       "mean     174.007529      0.048635     19.528314     18.495397     17.893314   \n",
       "std      179.404607      0.724706      2.194382      1.931732      1.773068   \n",
       "min        0.000165     -1.243447      8.985260      6.618781      6.940934   \n",
       "25%        0.502112     -0.569497     18.465448     17.573668     17.055212   \n",
       "50%        0.969110      0.075373     19.967171     18.960104     18.355196   \n",
       "75%      359.492904      0.682301     21.087143     19.793398     19.087181   \n",
       "max      359.999933      1.273383     22.999374     24.802490     27.166468   \n",
       "\n",
       "         CLASS_SDSS  \n",
       "count  15645.000000  \n",
       "mean       4.885331  \n",
       "std        1.449708  \n",
       "min        3.000000  \n",
       "25%        3.000000  \n",
       "50%        6.000000  \n",
       "75%        6.000000  \n",
       "max        6.000000  \n",
       "\n",
       "[8 rows x 40 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uki823_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       12535\n",
       "16       2464\n",
       "1024      533\n",
       "1040      108\n",
       "1           5\n",
       "Name: QUALITY, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uki823_df['QUALITY'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtered_uki823 = uki823_df.iloc[list(np.where(-uki823_df['QUALITY'].isin([1024, 1040]))[0]),]\n",
    "#filtered_uki823.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4537, 3612,    0,    0],\n",
       "       [1225, 6191,    0,    0],\n",
       "       [  11,    2,    0,    0],\n",
       "       [  40,   27,    0,    0]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Normalise SDSS class labels. Form confusion matrix\n",
    "normalise_sdss_class(uki823_df)\n",
    "uki823_df[['CLASS', 'CLASS_SDSS']]\n",
    "confusion_matrix(uki823_df['CLASS'], uki823_df['CLASS_SDSS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create first raw dataset\n",
    "data_x_raw = uki823_df.iloc[:,:-1]\n",
    "data_y_raw =uki823_df['CLASS_SDSS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split raw dataset into raw train,val,test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "random_state = 1\n",
    "X_train_raw,X_test_raw,y_train,y_test = train_test_split(data_x_raw,data_y_raw,test_size=0.1,random_state=random_state)\n",
    "X_train_raw,X_val_raw,y_train,y_val = train_test_split(X_train_raw,y_train,test_size=2./9,random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RA</th>\n",
       "      <th>DEC</th>\n",
       "      <th>XMIN</th>\n",
       "      <th>XMAX</th>\n",
       "      <th>YMIN</th>\n",
       "      <th>YMAX</th>\n",
       "      <th>AREA</th>\n",
       "      <th>IPEAK</th>\n",
       "      <th>COSMAG</th>\n",
       "      <th>ISKY</th>\n",
       "      <th>...</th>\n",
       "      <th>QUALITY</th>\n",
       "      <th>N(0,1)</th>\n",
       "      <th>PRFMAG</th>\n",
       "      <th>C_COSMAG</th>\n",
       "      <th>C_PRFMAG</th>\n",
       "      <th>RA_SDSS</th>\n",
       "      <th>DEC_SDSS</th>\n",
       "      <th>GMAG_SDSS</th>\n",
       "      <th>RMAG_SDSS</th>\n",
       "      <th>IMAG_SDSS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>628210746</td>\n",
       "      <td>-1176630</td>\n",
       "      <td>21469430</td>\n",
       "      <td>21485425</td>\n",
       "      <td>12697944</td>\n",
       "      <td>12709944</td>\n",
       "      <td>110</td>\n",
       "      <td>28187956</td>\n",
       "      <td>-22062</td>\n",
       "      <td>17845382</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-177</td>\n",
       "      <td>-22180</td>\n",
       "      <td>16.299</td>\n",
       "      <td>15.906</td>\n",
       "      <td>359.938326</td>\n",
       "      <td>-0.674138</td>\n",
       "      <td>19.356489</td>\n",
       "      <td>17.871933</td>\n",
       "      <td>16.739737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>883647</td>\n",
       "      <td>-1937461</td>\n",
       "      <td>18422221</td>\n",
       "      <td>18435217</td>\n",
       "      <td>10360939</td>\n",
       "      <td>10374939</td>\n",
       "      <td>111</td>\n",
       "      <td>29238444</td>\n",
       "      <td>-22154</td>\n",
       "      <td>17764206</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-991</td>\n",
       "      <td>-22265</td>\n",
       "      <td>16.227</td>\n",
       "      <td>15.813</td>\n",
       "      <td>0.506194</td>\n",
       "      <td>-1.110286</td>\n",
       "      <td>18.609985</td>\n",
       "      <td>20.223934</td>\n",
       "      <td>18.597603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>626820565</td>\n",
       "      <td>-225778</td>\n",
       "      <td>25746317</td>\n",
       "      <td>25752316</td>\n",
       "      <td>15617966</td>\n",
       "      <td>15625966</td>\n",
       "      <td>25</td>\n",
       "      <td>2608574</td>\n",
       "      <td>-18898</td>\n",
       "      <td>17632718</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5282</td>\n",
       "      <td>-19766</td>\n",
       "      <td>18.305</td>\n",
       "      <td>18.526</td>\n",
       "      <td>359.141781</td>\n",
       "      <td>-0.129471</td>\n",
       "      <td>20.414120</td>\n",
       "      <td>19.358303</td>\n",
       "      <td>18.915371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53294</td>\n",
       "      <td>-10961</td>\n",
       "      <td>20976557</td>\n",
       "      <td>20992553</td>\n",
       "      <td>16275941</td>\n",
       "      <td>16293941</td>\n",
       "      <td>180</td>\n",
       "      <td>46620048</td>\n",
       "      <td>-23110</td>\n",
       "      <td>18452752</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>-393</td>\n",
       "      <td>-23230</td>\n",
       "      <td>15.539</td>\n",
       "      <td>14.770</td>\n",
       "      <td>0.030579</td>\n",
       "      <td>-0.006282</td>\n",
       "      <td>16.176212</td>\n",
       "      <td>15.634457</td>\n",
       "      <td>15.433255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>626725557</td>\n",
       "      <td>834940</td>\n",
       "      <td>26040239</td>\n",
       "      <td>26048237</td>\n",
       "      <td>18876967</td>\n",
       "      <td>18885967</td>\n",
       "      <td>43</td>\n",
       "      <td>7318124</td>\n",
       "      <td>-20160</td>\n",
       "      <td>17651086</td>\n",
       "      <td>...</td>\n",
       "      <td>1024</td>\n",
       "      <td>28</td>\n",
       "      <td>-20557</td>\n",
       "      <td>17.644</td>\n",
       "      <td>17.667</td>\n",
       "      <td>359.087359</td>\n",
       "      <td>0.478322</td>\n",
       "      <td>20.911127</td>\n",
       "      <td>19.339987</td>\n",
       "      <td>17.994114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          RA      DEC      XMIN      XMAX      YMIN      YMAX  AREA     IPEAK  \\\n",
       "0  628210746 -1176630  21469430  21485425  12697944  12709944   110  28187956   \n",
       "1     883647 -1937461  18422221  18435217  10360939  10374939   111  29238444   \n",
       "2  626820565  -225778  25746317  25752316  15617966  15625966    25   2608574   \n",
       "3      53294   -10961  20976557  20992553  16275941  16293941   180  46620048   \n",
       "4  626725557   834940  26040239  26048237  18876967  18885967    43   7318124   \n",
       "\n",
       "   COSMAG      ISKY    ...      QUALITY  N(0,1)  PRFMAG  C_COSMAG  C_PRFMAG  \\\n",
       "0  -22062  17845382    ...            0    -177  -22180    16.299    15.906   \n",
       "1  -22154  17764206    ...            0    -991  -22265    16.227    15.813   \n",
       "2  -18898  17632718    ...            0    5282  -19766    18.305    18.526   \n",
       "3  -23110  18452752    ...           16    -393  -23230    15.539    14.770   \n",
       "4  -20160  17651086    ...         1024      28  -20557    17.644    17.667   \n",
       "\n",
       "      RA_SDSS  DEC_SDSS  GMAG_SDSS  RMAG_SDSS  IMAG_SDSS  \n",
       "0  359.938326 -0.674138  19.356489  17.871933  16.739737  \n",
       "1    0.506194 -1.110286  18.609985  20.223934  18.597603  \n",
       "2  359.141781 -0.129471  20.414120  19.358303  18.915371  \n",
       "3    0.030579 -0.006282  16.176212  15.634457  15.433255  \n",
       "4  359.087359  0.478322  20.911127  19.339987  17.994114  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_raw = X_train_raw.reset_index(drop=True)\n",
    "X_val_raw = X_val_raw.reset_index(drop=True)\n",
    "X_test_raw = X_test_raw.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "y_val = y_val.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "\n",
    "X_train_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtering poor quality images\n",
    "X_train_filtered = deepcopy(X_train_raw.iloc[list(np.where(-X_train_raw['QUALITY'].isin([1024, 1040]))[0]),])\n",
    "y_train_filtered = deepcopy(y_train.iloc[list(np.where(-X_train_raw['QUALITY'].isin([1024, 1040]))[0]),])\n",
    "\n",
    "X_val_filtered = deepcopy(X_val_raw.iloc[list(np.where(-X_val_raw['QUALITY'].isin([1024, 1040]))[0]),])\n",
    "y_val_filtered = deepcopy(y_val.iloc[list(np.where(-X_val_raw['QUALITY'].isin([1024, 1040]))[0]),])\n",
    "\n",
    "X_test_filtered = deepcopy(X_test_raw.iloc[list(np.where(-X_test_raw['QUALITY'].isin([1024, 1040]))[0]),])\n",
    "y_test_filtered = deepcopy(y_test.iloc[list(np.where(-X_test_raw['QUALITY'].isin([1024, 1040]))[0]),])\n",
    "\n",
    "#Reset indices\n",
    "X_train_filtered = X_train_filtered.reset_index(drop=True)\n",
    "X_val_filtered = X_val_filtered.reset_index(drop=True)\n",
    "X_test_filtered = X_test_filtered.reset_index(drop=True)\n",
    "\n",
    "y_train_filtered = y_train_filtered.reset_index(drop=True)\n",
    "y_val_filtered = y_val_filtered.reset_index(drop=True)\n",
    "y_test_filtered = y_test_filtered.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define classification function\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score,roc_auc_score\n",
    "\n",
    "def Classify_Function(x_train,y_train,x_val,y_val):\n",
    "    names = [\"Logistic Regression\", #\"Linear SVM\", \"RBF SVM\",\n",
    "             #\"Decision Tree\",\n",
    "             \"Random Forest\", \"Neural Net (Multi-layer perceptron)\"]\n",
    "\n",
    "    classifiers = [\n",
    "        LogisticRegression(),\n",
    "        #SVC(kernel=\"linear\", probability=True, random_state=random_state),\n",
    "        #SVC(kernel='rbf', probability=True, random_state=random_state),\n",
    "        #DecisionTreeClassifier(max_depth=10),\n",
    "        RandomForestClassifier(max_depth=10, n_estimators=50,random_state=random_state),\n",
    "        MLPClassifier(max_iter=1000, random_state=random_state)]\n",
    "\n",
    "    ca_score = {} # Classification accuracy\n",
    "    F1_scores = {} #F1 scores\n",
    "    tr_score = {}\n",
    "    tr_F1 = {}\n",
    "\n",
    "    for name, clf in zip(names, classifiers):\n",
    "        clf.fit(x_train, y_train)\n",
    "        tr_score[name] = clf.score(x_train, y_train)\n",
    "        ca_score[name] = clf.score(x_val, y_val)\n",
    "        tr_F1[name] = f1_score(y_train, clf.predict(x_train), average='macro')\n",
    "        F1_scores[name] = f1_score(y_val,clf.predict(x_val),average='macro')\n",
    "\n",
    "    print('Classification performance on validation set:')\n",
    "    for clf in names:\n",
    "        print (\"{}, training accuracy: {:.3f}, training f1: {:.3f}\".format(clf, tr_score[clf], tr_F1[clf]))\n",
    "        print (\"{}, accuracy: {:.3f}, f1-score: {:.3f}\\n\\n\".format(clf, ca_score[clf], F1_scores[clf]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classify the raw data\n",
    "Classify_Function(X_train_raw,y_train,X_val_raw,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Create distribution plots of the features split by classes\n",
    "labels = np.array([1,2])\n",
    "fig, ax = plt.subplots((len(X_train_raw.columns)), labels.size, figsize=(15,45), sharey = 'row', sharex = 'row')\n",
    "\n",
    "\n",
    "for ii, feat in enumerate(X_train_raw):\n",
    "    for jj, clas in enumerate(labels):\n",
    "        sns.distplot(X_train_raw[y_train==clas][feat], ax=ax[ii][jj], kde=True)\n",
    "        ax[ii][jj].xaxis.label.set_visible(False)\n",
    "           \n",
    "[ax[0][ii].set_title(\"Class {}\".format(clas)) for ii, clas in enumerate(labels)]\n",
    "[ax[ii][0].set_ylabel(\"{}\".format(feat)) for ii, feat in enumerate(X_train_raw)]\n",
    "        \n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter out irrelevant columns\n",
    "X_train = deepcopy(X_train_filtered.iloc[:,relevant_indices[0:(len(relevant_indices)-1)]])\n",
    "X_val = deepcopy(X_val_filtered.iloc[:,relevant_indices[0:(len(relevant_indices)-1)]])\n",
    "X_test = deepcopy(X_test_filtered.iloc[:,relevant_indices[0:(len(relevant_indices)-1)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train_filtered\n",
    "y_val = y_val_filtered\n",
    "y_test = y_test_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AREA', 'IPEAK', 'COSMAG', 'ISKY', 'A_U', 'B_U', 'THETA_U', 'A_I',\n",
       "       'B_I', 'THETA_I', 'BLEND', 'QUALITY', 'PRFMAG', 'C_COSMAG', 'C_PRFMAG',\n",
       "       'RA_SDSS', 'DEC_SDSS', 'GMAG_SDSS', 'RMAG_SDSS', 'IMAG_SDSS',\n",
       "       'ELLIPTICITY', 'FILLING_FACTOR'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extracting relevant columns and adding ellips and FF to X datasets\n",
    "X_train = add_filling_factor(add_ellipticity_df(X_train))\n",
    "X_val = add_filling_factor(add_ellipticity_df(X_val))\n",
    "X_test = add_filling_factor(add_ellipticity_df(X_test))\n",
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identify features that look interesting...\n",
    "interesting_cols = [0, 1, 2, 10, 11, 21]\n",
    "\n",
    "# Need to add X_train and y_train back together here\n",
    "temp = deepcopy(X_train)\n",
    "temp['ys'] = y_train\n",
    "\n",
    "sns.pairplot(temp, vars=X_train.columns[interesting_cols], hue='ys', diag_kind = 'kde', plot_kws={'s' : 6})\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification performance on validation set:\n",
      "Logistic Regression, training accuracy: 0.859, training f1: 0.849\n",
      "Logistic Regression, accuracy: 0.868, f1-score: 0.860\n",
      "\n",
      "\n",
      "Random Forest, training accuracy: 0.942, training f1: 0.938\n",
      "Random Forest, accuracy: 0.873, f1-score: 0.866\n",
      "\n",
      "\n",
      "Neural Net (Multi-layer perceptron), training accuracy: 0.918, training f1: 0.912\n",
      "Neural Net (Multi-layer perceptron), accuracy: 0.900, f1-score: 0.893\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Scale dataset and classify\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler().fit(X_train.astype('float64'))\n",
    "\n",
    "\n",
    "Classify_Function(sc.transform(X_train.astype('float64')),\n",
    "                  y_train,\n",
    "                  sc.transform(X_val.astype('float64')),\n",
    "                  y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.55730733 0.64164976 0.71667486 0.79010813 0.83607921 0.87713143\n",
      " 0.91155399 0.93730387 0.95520712 0.96861365 0.98022661 0.99028771\n",
      " 0.99358854 0.99629406 0.99806023 0.99873332 0.99921006 0.99959075\n",
      " 0.99979064 0.99990239 0.9999999  1.        ]\n"
     ]
    }
   ],
   "source": [
    "#Fitting PCA to scaled training data. 9 PC's\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA().fit(sc.transform(X_train.astype('float64')))\n",
    "print(np.cumsum(pca.explained_variance_ratio_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate PCA scores for all datasets. 11 PCs\n",
    "eleven_pcs = PCA(n_components = 11).fit(sc.transform(X_train.astype('float64')))\n",
    "pc_scores_train = eleven_pcs.transform(sc.transform(X_train.astype('float64')))\n",
    "pc_scores_val = eleven_pcs.transform(sc.transform(X_val.astype('float64')))\n",
    "pc_scores_test = eleven_pcs.transform(sc.transform(X_test.astype('float64')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define function to plot PC directions\n",
    "def scatter_2d_label(X_2d, y, s=2, alpha=0.5, lw=2):\n",
    "    \"\"\"Visualuse a 2D embedding with corresponding labels.\n",
    "    \n",
    "    X_2d : ndarray, shape (n_samples,2)\n",
    "        Low-dimensional feature representation.\n",
    "    \n",
    "    y : ndarray, shape (n_samples,)\n",
    "        Labels corresponding to the entries in X_2d.\n",
    "        \n",
    "    s : float\n",
    "        Marker size for scatter plot.\n",
    "    \n",
    "    alpha : float\n",
    "        Transparency for scatter plot.\n",
    "        \n",
    "    lw : float\n",
    "        Linewidth for scatter plot.\n",
    "    \"\"\"\n",
    "    targets = np.unique(y)\n",
    "    colors = sns.color_palette(n_colors=targets.size)\n",
    "    for color, target in zip(colors, targets):\n",
    "        plt.scatter(X_2d[y == target, 0], X_2d[y == target, 1], color=color, label=target, s=s, alpha=alpha, lw=lw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_1 = 0# First dimension\n",
    "dim_2 = 1 # Second dimension\n",
    "plt.figure(figsize=(8,5)) # Initialise a figure instance with defined size\n",
    "scatter_2d_label(pc_scores_train[:, [dim_1,dim_2]], y_train)\n",
    "plt.legend(loc='center left', bbox_to_anchor=[1.01, 0.5], scatterpoints=3) # Add a legend outside the plot at specified point\n",
    "plt.xlabel('Dim {}'.format(dim_1))\n",
    "plt.ylabel('Dim {}'.format(dim_2))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification performance on validation set:\n",
      "Logistic Regression, training accuracy: 0.814, training f1: 0.800\n",
      "Logistic Regression, accuracy: 0.816, f1-score: 0.803\n",
      "\n",
      "\n",
      "Random Forest, training accuracy: 0.896, training f1: 0.889\n",
      "Random Forest, accuracy: 0.805, f1-score: 0.793\n",
      "\n",
      "\n",
      "Neural Net (Multi-layer perceptron), training accuracy: 0.858, training f1: 0.850\n",
      "Neural Net (Multi-layer perceptron), accuracy: 0.830, f1-score: 0.822\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Classify_Function(pc_scores_train,y_train,pc_scores_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_filtered.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#One hot encode SSS class labels\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()\n",
    "X=enc.fit_transform(X_train_filtered['CLASS'].values.reshape(-1,1)).toarray()\n",
    "dfOneHot = pd.DataFrame(X, columns = [\"Class_\"+str(int(i)) for i in range(X.shape[1])])\n",
    "dfOneHot = pd.concat([dfOneHot, X_train_filtered['N(0,1)']], axis=1)\n",
    "X_train_SSS = pd.concat([X_train, dfOneHot], axis=1)\n",
    "\n",
    "\n",
    "X=enc.fit_transform(X_val_filtered['CLASS'].values.reshape(-1,1)).toarray()\n",
    "dfOneHot = pd.DataFrame(X, columns = [\"Class_\"+str(int(i)) for i in range(X.shape[1])])\n",
    "dfOneHot = pd.concat([dfOneHot, X_val_filtered['N(0,1)']], axis=1)\n",
    "X_val_SSS = pd.concat([X_val, dfOneHot], axis=1)\n",
    "\n",
    "\n",
    "X=enc.fit_transform(X_test_filtered['CLASS'].values.reshape(-1,1)).toarray()\n",
    "dfOneHot = pd.DataFrame(X, columns = [\"Class_\"+str(int(i)) for i in range(X.shape[1])])\n",
    "dfOneHot = pd.concat([dfOneHot, X_test_filtered['N(0,1)']], axis=1)\n",
    "X_test_SSS = pd.concat([X_test, dfOneHot], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification performance on validation set:\n",
      "Logistic Regression, training accuracy: 0.860, training f1: 0.850\n",
      "Logistic Regression, accuracy: 0.867, f1-score: 0.859\n",
      "\n",
      "\n",
      "Random Forest, training accuracy: 0.949, training f1: 0.946\n",
      "Random Forest, accuracy: 0.871, f1-score: 0.865\n",
      "\n",
      "\n",
      "Neural Net (Multi-layer perceptron), training accuracy: 0.911, training f1: 0.906\n",
      "Neural Net (Multi-layer perceptron), accuracy: 0.898, f1-score: 0.892\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc2 = StandardScaler().fit(X_train_SSS.astype('float64'))\n",
    "\n",
    "\n",
    "Classify_Function(sc2.transform(X_train_SSS.astype('float64')),\n",
    "                  y_train,\n",
    "                  sc2.transform(X_val_SSS.astype('float64')),\n",
    "                  y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping correlated features\n",
    "X_train_unc = X_train.drop(['COSMAG','A_U','B_U','THETA_U','PRFMAG','RA_SDSS','DEC_SDSS'], axis=1)\n",
    "X_val_unc = X_val.drop(['COSMAG','A_U','B_U','THETA_U','PRFMAG','RA_SDSS','DEC_SDSS'], axis=1)\n",
    "X_test_unc = X_test.drop(['COSMAG','A_U','B_U','THETA_U','PRFMAG','RA_SDSS','DEC_SDSS'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification performance on validation set:\n",
      "Logistic Regression, training accuracy: 0.849, training f1: 0.839\n",
      "Logistic Regression, accuracy: 0.855, f1-score: 0.847\n",
      "\n",
      "\n",
      "Random Forest, training accuracy: 0.942, training f1: 0.938\n",
      "Random Forest, accuracy: 0.878, f1-score: 0.871\n",
      "\n",
      "\n",
      "Neural Net (Multi-layer perceptron), training accuracy: 0.913, training f1: 0.907\n",
      "Neural Net (Multi-layer perceptron), accuracy: 0.902, f1-score: 0.896\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sc_unc = StandardScaler().fit(X_train_unc.astype('float64'))\n",
    "\n",
    "\n",
    "Classify_Function(sc_unc.transform(X_train_unc.astype('float64')),\n",
    "                  y_train,\n",
    "                  sc_unc.transform(X_val_unc.astype('float64')),\n",
    "                  y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_list=['AREA', 'IPEAK', 'COSMAG', 'ISKY', 'A_U', 'B_U', 'A_I', 'B_I', 'PRFMAG',\n",
    "       'C_COSMAG', 'C_PRFMAG', 'GMAG_SDSS', 'RMAG_SDSS', 'IMAG_SDSS',\n",
    "       'ELLIPTICITY', 'FILLING_FACTOR', 'Class_3']\n",
    "\n",
    "#sc2 = StandardScaler().fit(X_train_SSS.astype('float64'))\n",
    "#sc_important = StandardScaler.fit(X_train_SSS.loc[:,var_list])\n",
    "X_train_imp = X_train_SSS.loc[:,var_list]\n",
    "sc_imp = StandardScaler().fit(X_train_imp.astype('float64'))\n",
    "#X_train_impsc = (sc_important.transform((X_train_SSS.loc[:,var_list])))\n",
    "#X_train_important.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "X_train_important = (sc_imp.transform(X_train_imp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "cv = KFold(n_splits=3, shuffle=True, random_state=random_state)\n",
    "mlp_clf = MLPClassifier(random_state=random_state)\n",
    "\n",
    "def objective_mlp(params):\n",
    "    number_hidden_units, alpha = params\n",
    "\n",
    "    mlp_clf.set_params(hidden_layer_sizes = (number_hidden_units,),\n",
    "                      alpha=alpha)\n",
    "\n",
    "    return -np.mean(cross_val_score(mlp_clf, X_train_important, y_train, cv=cv, n_jobs=-1,\n",
    "                                    scoring=\"accuracy\"))\n",
    "\n",
    "space  = [(10, 1000),                       # number of hidden units\n",
    "          (10**-8, 1)]                      # alpha\n",
    "x0 = [100, 10**-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score with Bayesian optimisation: -0.898\n",
      "Best parameters with Bayesian optimisation:\n",
      "-hidden layer size: (988,)\n",
      "-alpha: 0.00027699662816958016\n"
     ]
    }
   ],
   "source": [
    "from skopt import gp_minimize\n",
    "\n",
    "res_gp = gp_minimize(objective_mlp, space, x0=x0, n_calls=25, random_state=random_state, n_random_starts=5)\n",
    "print(\"Best score with Bayesian optimisation: {:.3f}\".format(res_gp.fun))\n",
    "print(\"Best parameters with Bayesian optimisation:\\n-hidden layer size: ({},)\\n-alpha: {}\"\n",
    "      .format(res_gp.x[0],res_gp.x[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convergence plot\n",
    "from skopt.plots import plot_convergence\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plot_convergence(res_gp)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy on validation set: 0.901\n",
      "Classification accuracy on test set: 0.907\n"
     ]
    }
   ],
   "source": [
    "# Train final model and report accuracy on validation and test sets\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "mlp_opt = MLPClassifier(random_state=random_state,\n",
    "                        hidden_layer_sizes = (res_gp.x[0],),\n",
    "                        alpha=res_gp.x[1])\n",
    "mlp_opt.fit(sc.transform(X_train.astype('float64')),y_train)\n",
    "print(\"Classification accuracy on validation set: {:.3f}\".format(accuracy_score(y_val, mlp_opt.predict(sc.transform(X_val.astype('float64'))))))\n",
    "print(\"Classification accuracy on test set: {:.3f}\".format(accuracy_score(y_test, mlp_opt.predict(sc.transform(X_test.astype('float64'))))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for MLP classifier: hidden layer size: (120,), alpha: 1e-07, best cross-validated score: 0.888\n",
      "Classification accuracy on validation set: 0.900\n",
      "CPU times: user 5min 45s, sys: 31.3 s, total: 6min 16s\n",
      "Wall time: 3min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning) \n",
    "\n",
    "# MLP with variable hidden layer size and alpha, score: log-loss\n",
    "cv = KFold(n_splits=3, shuffle=True, random_state=random_state)\n",
    "mlp = MLPClassifier(random_state=random_state, solver='adam')\n",
    "parameters = {'hidden_layer_sizes' : [(30*(i),) for i in range(3,5)], 'alpha' : np.logspace(-7,0,7)}\n",
    "mlp_clf = GridSearchCV(mlp, param_grid=parameters, scoring='f1_macro')\n",
    "\n",
    "mlp_clf.fit(sc_unc.transform(X_train_unc.astype('float64')),\n",
    "            y_train)\n",
    "\n",
    "print(\"Best parameters for MLP classifier: hidden layer size: {}, alpha: {}, best cross-validated score: {:.3f}\".\n",
    "      format(mlp_clf.best_params_[\"hidden_layer_sizes\"], mlp_clf.best_params_[\"alpha\"], mlp_clf.best_score_))\n",
    "print(\"Classification accuracy on validation set: {:.3f}\".format(f1_score(y_val, mlp_clf.predict(sc_unc.transform(X_val_unc.astype('float64'))), average='macro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test f1: 0.8959658084019597\n",
      "test accuracy: 0.9038076152304609\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "final = MLPClassifier(hidden_layer_sizes=(120,), \n",
    "                      solver='adam',\n",
    "                      alpha=1e-07,\n",
    "                      random_state=random_state)\n",
    "\n",
    "final.fit(sc.transform(X_train.astype('float64')),\n",
    "            y_train)\n",
    "\n",
    "print(\"test f1:\", f1_score(y_test, final.predict(sc.transform(X_test.astype('float64'))), average='macro'))\n",
    "print(\"test accuracy:\", accuracy_score(y_test, final.predict(sc.transform(X_test.astype('float64')))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification performance on test set:\n",
      "Random Forest, accuracy: 0.885, f1-score: 0.875\n",
      "\n",
      "\n",
      "Neural Net (Multi-layer perceptron), accuracy: 0.912, f1-score: 0.905\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classifying the test set\n",
    "sc3 = StandardScaler().fit(X_train.astype('float64'))\n",
    "#sc3.transform(X_train.astype('float64'))\n",
    "final_names = [\"Random Forest\", \"Neural Net (Multi-layer perceptron)\"]\n",
    "\n",
    "final_classifiers = [RandomForestClassifier(max_depth=10, n_estimators=50,random_state=random_state), \n",
    "                     MLPClassifier(random_state=random_state, hidden_layer_sizes = (res_gp.x[0],),\n",
    "                    alpha=res_gp.x[1])]\n",
    "\n",
    "ca_score = {} # Classification accuracy\n",
    "F1_scores = {} #F1 scores\n",
    "\n",
    "for name, clf in zip(final_names, final_classifiers):\n",
    "    clf.fit(sc3.transform(X_train.astype('float64')), y_train)\n",
    "    ca_score[name] = clf.score(sc3.transform(X_test.astype('float64')), y_test)\n",
    "    F1_scores[name] = f1_score(y_test,clf.predict(sc3.transform(X_test.astype('float64'))),average='macro')\n",
    "    \n",
    "print('Classification performance on test set:')\n",
    "for clf in final_names:\n",
    "    print (\"{}, accuracy: {:.3f}, f1-score: {:.3f}\\n\\n\".format(clf, ca_score[clf], F1_scores[clf]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf4 = MLPClassifier(random_state=random_state, hidden_layer_sizes = (res_gp.x[0],),\n",
    "                    alpha=res_gp.x[1])\n",
    "clf4.fit(sc3.transform(X_train.astype('float64')), y_train)\n",
    "test_predictions = clf4.predict(sc3.transform(X_test.astype('float64')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12.    , 12.9375, 13.875 , 14.8125, 15.75  , 16.6875, 17.625 ,\n",
       "       18.5625, 19.5   ])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist, edges = np.histogram(X_test['C_COSMAG'],bins=8,range=(12,19.5))\n",
    "edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_bin = lambda df,index: int(8*(df.iloc[index] - df.min())/(df.max() - df.min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_objects = np.zeros(shape=(8,1))\n",
    "bin_galaxies = np.zeros(shape=(8,1))\n",
    "bin_stars = np.zeros(shape=(8,1))\n",
    "classified_galaxies = np.zeros(shape=(8,1))\n",
    "classified_stars = np.zeros(shape=(8,1))\n",
    "correct_galaxies = np.zeros(shape=(8,1))\n",
    "correct_stars = np.zeros(shape=(8,1))\n",
    "\n",
    "\n",
    "for i in range(len(X_test['C_COSMAG'])):\n",
    "    bin_num = calc_bin(X_test['C_COSMAG'],i) - 1\n",
    "    bin_objects[bin_num] += 1\n",
    "    if y_test.iloc[i] == 1:\n",
    "        bin_galaxies[bin_num] += 1\n",
    "    elif y_test.iloc[i] == 2:\n",
    "        bin_stars[bin_num] += 1\n",
    "        \n",
    "    if test_predictions[i] == 1:\n",
    "        classified_galaxies[bin_num] += 1\n",
    "    elif test_predictions[i] == 2:\n",
    "        classified_stars[bin_num] += 1\n",
    "        \n",
    "    if test_predictions[i] == 1 and y_test.iloc[i] == 1:\n",
    "        correct_galaxies[bin_num] += 1\n",
    "    elif test_predictions[i] == 2 and y_test.iloc[i] == 2:\n",
    "        correct_stars[bin_num] += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage_correct = [100*(correct_galaxies[i]+correct_stars[i])/bin_objects[i] for i in range(len(bin_objects))]\n",
    "final_results = np.hstack((bin_objects,bin_galaxies,bin_stars,classified_galaxies,correct_galaxies,classified_stars,correct_stars,percentage_correct))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 37.        ,  13.        ,  24.        ,  14.        ,\n",
       "         10.        ,  23.        ,  20.        ,  81.08108108],\n",
       "       [ 87.        ,   1.        ,  86.        ,   1.        ,\n",
       "          1.        ,  86.        ,  86.        , 100.        ],\n",
       "       [105.        ,   7.        ,  98.        ,   5.        ,\n",
       "          5.        , 100.        ,  98.        ,  98.0952381 ],\n",
       "       [152.        ,  25.        , 127.        ,  26.        ,\n",
       "         25.        , 126.        , 126.        ,  99.34210526],\n",
       "       [239.        ,  71.        , 168.        ,  65.        ,\n",
       "         63.        , 174.        , 166.        ,  95.81589958],\n",
       "       [482.        , 192.        , 290.        , 199.        ,\n",
       "        175.        , 283.        , 266.        ,  91.49377593],\n",
       "       [390.        , 218.        , 172.        , 223.        ,\n",
       "        186.        , 167.        , 135.        ,  82.30769231],\n",
       "       [  5.        ,   4.        ,   1.        ,   5.        ,\n",
       "          4.        ,   0.        ,   0.        ,  80.        ]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
